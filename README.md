# Data Cleaning with Python


### Outline

- Project Overview
- Dataset Used
- Key Findings
- Libraries Used


## Project Overview
This project demonstrates essential data-cleaning techniques using Python libraries such as `Pandas` and `NumPy`. The dataset is processed through several preprocessing steps, including:

- Removing duplicate entries to ensure data integrity
- Handling outlier and missing values through imputation or removal
- Standardizing data formats for consistency across the dataset
- Transforming features to ensure the data is clean, suitable, and well-prepared for analysis or modeling (optional)

These steps prepare the data for more accurate analysis and modeling.

You can view the full process in the Jupyter Notebook [here](https://github.com/Lillian1070/showcase_python_dataCleaning_1/blob/main/kaggle_coffeeBean_dataCleaning.ipynb). 


## Dataset Used
The dataset used in this project is sourced from Kaggle. You can access it [here](https://www.kaggle.com/datasets/fatihb/coffee-quality-data-cqi).


## Key Findings
During the data-cleaning process, several important observations were made:

- Outliers: Extreme values were detected in certain numerical columns, and appropriate transformations or flags were applied
- Missing Values: Some key attributes had missing values, which were handled through imputation or removal
- Inconsistent Formatting: Data entries contained formatting inconsistencies, which were standardized for consistency
- Categorical Transformations: Some categorical variables were modified to enhance interpretability and usability

These improvements ensure the dataset is clean and ready for further exploration and analysis.


## Libraries Used
- **Pandas**: For data manipulation, cleaning, and handling dataframes
- **NumPy**: For handling numerical operations and missing values
- **Matplotlib**: For data visualization, including plotting graphs like histograms, scatter plots, etc.
- **Seaborn**: For statistical data visualization and enhanced graphical representations
- **SciPy**: For scientific and technical computing, including statistical tests and optimizations (e.g., Shapiro-Wilk test)
- **Counter**: For counting occurrences of elements in lists or collections
- **re**: For working with regular expressions to manipulate strings and text







_Iâ€™d love to hear your thoughts! If you have any suggestions or questions, feel free to connect with me._


