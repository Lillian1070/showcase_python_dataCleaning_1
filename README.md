# Data Cleaning with Python


### Outline

- Project Overview
- Dataset Used
- Libraries Used


## Project Overview
This project demonstrates essential data-cleaning techniques using Python libraries such as `Pandas` and `NumPy`. The dataset is processed through several preprocessing steps, including:

- Removing duplicate entries to ensure data integrity
- Handling outlier and missing values through imputation or removal
- Standardizing data formats for consistency across the dataset
- Transforming features to ensure the data is clean, suitable, and well-prepared for analysis or modeling (optional)

These steps prepare the data for more accurate analysis and modeling.

You can view the full process in the Jupyter Notebook [here](https://github.com/Lillian1070/showcase_python_dataCleaning_1/blob/main/kaggle_coffeeBean_dataCleaning.ipynb). 


## Dataset Used
The dataset used in this project is sourced from Kaggle. You can access it [here](https://www.kaggle.com/datasets/fatihb/coffee-quality-data-cqi).

## Libraries Used
- **Pandas**: For data manipulation, cleaning, and handling dataframes
- **NumPy**: For handling numerical operations and missing values
- **Matplotlib**: For data visualization, including plotting graphs like histograms, scatter plots, etc.
- **Seaborn**: For statistical data visualization and enhanced graphical representations
- **SciPy**: For scientific and technical computing, including statistical tests and optimizations (e.g., Shapiro-Wilk test)
- **Counter**: For counting occurrences of elements in a collection
- **re**: For working with regular expressions to manipulate strings and text







_Iâ€™d love to hear your thoughts! If you have any suggestions or questions, feel free to connect with me._


